{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from morph_analysis import *\n",
    "import os, sys\n",
    "import pickle\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "import collections\n",
    "\n",
    "def dump(data, name):\n",
    "    filehandler = open(name, \"wb\")\n",
    "    pickle.dump(data, filehandler)\n",
    "    filehandler.close()\n",
    "def load(name):\n",
    "    filehandler = open(name, \"rb\")\n",
    "    return pickle.load(filehandler)\n",
    "\n",
    "morph = Morph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_Tag = load('storage/freq_Tag')\n",
    "#freq_TagWord = load('storage/freq_TagWord') # output probability를 구하기 위해\n",
    "#freq_Word = load('storage/freq_Word')\n",
    "#freq_pTagcTag = load('storage/freq_pTagcTag') # transition probability를 구하기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From morphological analysis (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '우선'\n",
    "result0 = [[['우', 0, 1, 'ENT', 'NNG NounV 우/NNG', 'XPN NounV 우/XPN', 'XSN NounV 우/XSN'],\n",
    "  ['서', 2, 3, 'ENT', 'VV VERB-REG3 서/VV'],\n",
    "  ['ㄴ', 4, 4, 'FUN', 'E VA-1-0 ㄴ/ETM']],\n",
    " [['우', 0, 1, 'ENT', 'NNG NounV 우/NNG', 'XPN NounV 우/XPN'],\n",
    "  ['선', 2, 4, 'ENT', 'NNG NounC 선/NNG']],\n",
    " [['우선', 0, 4, 'ENT', 'NNG NounC 우선/NNG']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '신고전주의정신을' \n",
    "morph_result = [[['신', 0, 2, 'ENT', 'NNG NounC 신/NNG', 'XPN NounC 신/XPN'],\n",
    "  ['고', 3, 4, 'ENT', 'NNG NounV 고/NNG'],\n",
    "  ['전', 5, 7, 'ENT', 'NNG NounC 전/NNG'],\n",
    "  ['주의', 8, 11, 'ENT', 'NNG NounV 주의/NNG'],\n",
    "  ['정', 12, 14, 'ENT', 'XSN NounC 정/XSN'],\n",
    "  ['신', 15, 17, 'ENT', 'NNG NounC 신/NNG', 'XSN NounC 신/XSN'],\n",
    "  ['을', 18, 20, 'FUN', 'E VA-1-3 을/ETM', 'J N-8-3 을/JKO']],\n",
    " [['신', 0, 2, 'ENT', 'NNG NounC 신/NNG', 'XPN NounC 신/XPN'],\n",
    "  ['고', 3, 4, 'ENT', 'NNG NounV 고/NNG'],\n",
    "  ['전', 5, 7, 'ENT', 'NNG NounC 전/NNG'],\n",
    "  ['주의', 8, 11, 'ENT', 'NNG NounV 주의/NNG'],\n",
    "  ['정신', 12, 17, 'ENT', 'NNG NounC 정신/NNG'],\n",
    "  ['을', 18, 20, 'FUN', 'J N-8-3 을/JKO']],\n",
    " [['신', 0, 2, 'ENT', 'NNG NounC 신/NNG', 'XPN NounC 신/XPN'],\n",
    "  ['고전', 3, 7, 'ENT', 'NNG NounC 고전/NNG'],\n",
    "  ['주의', 8, 11, 'ENT', 'NNG NounV 주의/NNG'],\n",
    "  ['정신', 12, 17, 'ENT', 'NNG NounC 정신/NNG'],\n",
    "  ['을', 18, 20, 'FUN', 'J N-8-3 을/JKO']],\n",
    " [['신', 0, 2, 'ENT', 'NNG NounC 신/NNG', 'XPN NounC 신/XPN'],\n",
    "  ['고전주의', 3, 11, 'ENT', 'NNG NounV 고전주의/NNG'],\n",
    "  ['정신', 12, 17, 'ENT', 'NNG NounC 정신/NNG'],\n",
    "  ['을', 18, 20, 'FUN', 'J N-8-3 을/JKO']],\n",
    " [['신고', 0, 4, 'ENT', 'NNG NounV 신고/NNG'],\n",
    "  ['전', 5, 7, 'ENT', 'NNG NounC 전/NNG'],\n",
    "  ['주의', 8, 11, 'ENT', 'NNG NounV 주의/NNG'],\n",
    "  ['정', 12, 14, 'ENT', 'XSN NounC 정/XSN'],\n",
    "  ['신', 15, 17, 'ENT', 'NNG NounC 신/NNG', 'XSN NounC 신/XSN'],\n",
    "  ['을', 18, 20, 'FUN', 'E VA-1-3 을/ETM', 'J N-8-3 을/JKO']],\n",
    " [['신고', 0, 4, 'ENT', 'NNG NounV 신고/NNG'],\n",
    "  ['전', 5, 7, 'ENT', 'NNG NounC 전/NNG'],\n",
    "  ['주의', 8, 11, 'ENT', 'NNG NounV 주의/NNG'],\n",
    "  ['정신', 12, 17, 'ENT', 'NNG NounC 정신/NNG'],\n",
    "  ['을', 18, 20, 'FUN', 'J N-8-3 을/JKO']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '본받자'\n",
    "result3 = [[['본', 0, 2, 'ENT', 'NNG NounC 본/NNG'],\n",
    "  ['받', 3, 5, 'ENT', 'VV VERB-REG 받/VV'],\n",
    "  ['자', 6, 7, 'FUN', 'E V-0-0 자/E']],\n",
    " [['본받', 0, 5, 'ENT', 'VV VERB-REG 본받/VV'], ['자', 6, 7, 'FUN', 'E V-0-0 자/E']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[['좁혀', 0, 4, 'ENT', 'VV VERB-REG4 좁히/VV'],\n",
    "  ['ㅆ다', 5, 7, 'FUN', 'E V-5-0 었/EP+다/EF']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# 형태소 조합이 20개인데, 이들을 모두 viterbi를 돌려 확률값을 구하고\n",
    "# 20개 중에 가장 높은 확률을 가지는 조합을 best로 선택한다.\n",
    "print(len(morph_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change morph-result to new format for POS (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'신'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['신', 15, 17, 'ENT', 'NNG NounC 신/NNG', 'XSN NounC 신/XSN']\n",
    "a[-1].split()[-1].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_text = '가까웠지만'\n",
    "# jamo = split_syllables(sample_text)\n",
    "# print(jamo)\n",
    "# restored_text = join_jamos(jamo)\n",
    "# print(restored_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['을/JKO']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'J N-8-3 을/JKO'.split()[-1].split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['었/EP', '다/EF']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'E V-5-0 었/EP+다/EF'.split()[-1].split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orgin_morph_idx(morph_result, idx):\n",
    "    new_morph_result = [[]] * len(morph_result)\n",
    "    \n",
    "    for i, case in enumerate(morph_result):\n",
    "        str_idx = idx\n",
    "        temp = []\n",
    "        for entry in case:\n",
    "            for pair in entry[-1].split()[-1].split('+'):\n",
    "                org_morph = pair.split('/')[0]\n",
    "                len_syllables = len(split_syllables(org_morph))\n",
    "                temp.append([org_morph, str_idx, str_idx+len_syllables-1])\n",
    "                #print([org_morph, str_idx, str_idx+len_syllables-1])\n",
    "                str_idx += len_syllables\n",
    "        new_morph_result[i] = temp\n",
    "        #print('===')\n",
    "    return new_morph_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_equal(cur_entry, list):\n",
    "    for entry in list:\n",
    "        if cur_entry[0] == entry[0]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def unique_morphems(morph_result):\n",
    "    uniqueEntry_list = []\n",
    "    \n",
    "    for case in morph_result:\n",
    "        for entry in case:\n",
    "            if check_equal(entry, uniqueEntry_list) == False:\n",
    "                uniqueEntry_list.append(entry)    \n",
    "\n",
    "    #sorted1 = sorted(uniqueEntry_list, key=lambda k: k[1])\n",
    "    sorted2 = sorted(uniqueEntry_list, key=lambda k: k[2])\n",
    "    return sorted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_for_viterbi(sent):\n",
    "    final_entry_list = []\n",
    "    str_idx = 0\n",
    "    space_idx = []\n",
    "        \n",
    "    for i, token in enumerate(sent.split()):\n",
    "        \n",
    "        morph_result = morph.extract(token)\n",
    "\n",
    "        final_entry_list += unique_morphems(orgin_morph_idx(morph_result, str_idx))\n",
    "        str_idx = unique_morphems(orgin_morph_idx(morph_result, str_idx))[-1][2]+1\n",
    "        \n",
    "        if not i==len(sent.split())-1:\n",
    "            space_idx.append(str_idx)\n",
    "        \n",
    "    return final_entry_list, space_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = '우선 신고전주의정신을 본받자'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['우', 0, 1],\n",
       " ['서', 2, 3],\n",
       " ['ㄴ', 4, 4],\n",
       " ['선', 2, 4],\n",
       " ['우선', 0, 4],\n",
       " ['신', 5, 7],\n",
       " ['고', 8, 9],\n",
       " ['신고', 5, 9],\n",
       " ['전', 10, 12],\n",
       " ['고전', 8, 12],\n",
       " ['주의', 13, 16],\n",
       " ['고전주의', 8, 16],\n",
       " ['정', 17, 19],\n",
       " ['정신', 17, 22],\n",
       " ['을', 23, 25],\n",
       " ['본', 26, 28],\n",
       " ['받', 29, 31],\n",
       " ['본받', 26, 31],\n",
       " ['자', 32, 33]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_for_viterbi(sent)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_collect_entry_anly = prepare_for_viterbi(sent)[0]\n",
    "len_target_word = prepare_for_viterbi(sent)[0][-1][-1]\n",
    "\n",
    "def recursive_merging(collection, index_set, path, list_global_cases):\n",
    "    temp_path = path[:]\n",
    "    for index in index_set:\n",
    "        path.append(index)\n",
    "        index_set = [e for e in collection if int(e[1]) == index[2]+1] # first position\n",
    "        if len(index_set) == 0: # the end point\n",
    "            # save to global and then game over\n",
    "            list_global_cases.append(path)\n",
    "        else:\n",
    "            # recursive keep going\n",
    "            recursive_merging(collection, index_set, path, list_global_cases) # recursive function\n",
    "        path = temp_path[:] # recursive돌아서 망가진 path 원래대로 복귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorting based on start index\n",
    "final_collect_entry_anly = sorted(final_collect_entry_anly, key = lambda x: int(x[1]))\n",
    "\n",
    "# 오류확인 1. 처음과 끝의 경계는 아래와 같이 체크하면 된다. (중간에 있는 오류는 다음단계에서 확인한다.)\n",
    "assert(final_collect_entry_anly[0][1] == 0) # 처음이 index 0으로 시작하지 않을 경우.\n",
    "assert(final_collect_entry_anly[-1][2] == len_target_word) # 마지막이 word길이만큼의 index가 아닐 경우.\n",
    "\n",
    "### merging / combining all cases using recursive function\n",
    "list_global_cases, path = [], []\n",
    "# filtering only index0 (Starting point to recursive function)\n",
    "index0_entry_anly_set = [ele for ele in final_collect_entry_anly if int(ele[1]) == 0] # first position\n",
    "# recursive merging\n",
    "recursive_merging(final_collect_entry_anly, index0_entry_anly_set, path, list_global_cases)\n",
    "\n",
    "\n",
    "# 오류확인 2. 처음부터 끝까지 이어지는 하나의 case도 없을 경우.\n",
    "fullpath_check = False\n",
    "for i in range(0, len(list_global_cases)):\n",
    "    if list_global_cases[i][-1][2] == len_target_word:\n",
    "        fullpath_check = True\n",
    "assert(fullpath_check == True) # 오류 난다면 사전 lookup 문제이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Sequence가 0에서부터 len_target_word-1까지 이어지지 않으면 삭제한다.\n",
    "for i, seq in enumerate(list_global_cases):\n",
    "    if seq[0][1] != 0 or seq[-1][2] != len_target_word:\n",
    "        list_global_cases[i] = 'to-be-deleted'\n",
    "# remove elements, which has 'to-be-deleted' in the first position        \n",
    "list_global_cases = [elem for elem in list_global_cases if elem != 'to-be-deleted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고', 8, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고', 8, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전', 8, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전', 8, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전주의', 8, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전주의', 8, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신고', 5, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['서', 2, 3],\n",
       "  ['ㄴ', 4, 4],\n",
       "  ['신고', 5, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고', 8, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고', 8, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전', 8, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전', 8, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전주의', 8, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전주의', 8, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신고', 5, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우', 0, 1],\n",
       "  ['선', 2, 4],\n",
       "  ['신고', 5, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고', 8, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고', 8, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전', 8, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전', 8, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전주의', 8, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신', 5, 7],\n",
       "  ['고전주의', 8, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신고', 5, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본', 26, 28],\n",
       "  ['받', 29, 31],\n",
       "  ['자', 32, 33]],\n",
       " [['우선', 0, 4],\n",
       "  ['신고', 5, 9],\n",
       "  ['전', 10, 12],\n",
       "  ['주의', 13, 16],\n",
       "  ['정신', 17, 22],\n",
       "  ['을', 23, 25],\n",
       "  ['본받', 26, 31],\n",
       "  ['자', 32, 33]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_global_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['우', 0, 1], ['서', 2, 3], ['ㄴ', 4, 4], ['선', 2, 4], ['우선', 0, 4]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[case for case in prepare_for_viterbi(sent)[0] if case[1] <= 4 and case[2] <= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Alogorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idxPair_tuple(list):\n",
    "    new_list = [0]*len(list)\n",
    "    str_idx = 0\n",
    "    for i, num in enumerate(list):\n",
    "        new_list[i] = (str_idx, num)\n",
    "        str_idx = num+1\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi(input):\n",
    "\n",
    "    entry_list = input[0]\n",
    "    end_idx = entry_list[-1][2]\n",
    "    space_idx = input[1]\n",
    "\n",
    "    ###\n",
    "    ### 2개 이상인 end index list (1개의 형태소를 결정해야되는 지점)\n",
    "    only_endIdx_list = [case[2] for case in entry_list]\n",
    "    many_endIdx_list = [item for item, count in collections.Counter(only_endIdx_list).items() if count > 1]\n",
    "    # many_endIdx_list 의미 \n",
    "    # ex. [4, 9, 12, 16, 31]이면 이 지점에서 하나의 형태소를 결정지어야 한다. (한국어 특성때문)\n",
    "    # 이 지점에서 결정짓지 않으면 viterbi라 하더라도 계산량이 매우 많아진다.\n",
    "    many_idxPair_list = idxPair_tuple(many_endIdx_list)\n",
    "    print(many_idxPair_list)\n",
    "#     ###\n",
    "#     ### start index 기준 엔트리 나열\n",
    "#     startIdx_entry_list = []\n",
    "#     for i in range(0, end_idx+1):\n",
    "#         entries = [ent for ent in prepare_for_viterbi(sent)[0] if ent[1] == i]\n",
    "#         if len(entries) != 0:\n",
    "#             startIdx_entry_list.append(entries)\n",
    "#     print(startIdx_entry_list)\n",
    "\n",
    "\n",
    "    for start, end in many_idxPair_list:\n",
    "        \n",
    "        # endIdx 이하 entry들 filtering\n",
    "        print([case for case in entry_list if case[1] >= start and case[2] <= end])\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (5, 9), (10, 12), (13, 16), (17, 31)]\n",
      "[['우', 0, 1], ['서', 2, 3], ['ㄴ', 4, 4], ['선', 2, 4], ['우선', 0, 4]]\n"
     ]
    }
   ],
   "source": [
    "viterbi(prepare_for_viterbi(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (5, 9), (10, 12), (13, 16), (17, 31)]\n",
      "[['우', 0, 1], ['서', 2, 3], ['ㄴ', 4, 4], ['선', 2, 4], ['우선', 0, 4]]\n"
     ]
    }
   ],
   "source": [
    "viterbi(prepare_for_viterbi(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph_result = list_global_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check all words in \n",
    "# 그냥 형태소 분석의 출력 경우의 수 각각 확률을 구해주고 비교하는 거라면... 영어처럼 viterbi를 수행해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_maxProb(tag_list, total_probState, i, j, prob_pTagcTag):\n",
    "    \n",
    "    cur_tag = tag_list[j]\n",
    "    temp = [0] * len(tag_list)\n",
    "    \n",
    "    for k, _ in enumerate(tag_list):\n",
    "        temp[k] = prob_pTagcTag[(tag_list[k], cur_tag)] * total_probState[i-1][k]\n",
    "    \n",
    "    argmax_idx = np.where(np.array(temp) == np.array(temp).max())\n",
    "    index = argmax_idx[0][0] # (array([3], dtype=int64),) -> [0][0]해줘야 index 3가 추출된다.\n",
    "    max_prob = np.array(temp).max()\n",
    "    \n",
    "    return max_prob, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob_TagWord' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-91e64110cc98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcur_syllable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmorph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# POS Tag 경우의 수\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutput_probState\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob_TagWord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_syllable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[1;31m### Step 2: Storing only maximum probabiliteis to each state by multiplying transition probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prob_TagWord' is not defined"
     ]
    }
   ],
   "source": [
    "all_pos_cases = []\n",
    "all_jointprob_cases = []\n",
    "prob_case = [0] * len(morph_result)\n",
    "\n",
    "tag_list = list(freq_Tag.keys()) # 주의: tag_list와 freq_Tag.keys()의 배열 순서는 다르다.\n",
    "\n",
    "for case in morph_result: # 형태소 분석 조합 경우의 수\n",
    "    \n",
    "    output_probState = [[0] * len(tag_list)] * len(case) \n",
    "    total_probState = [[0] * len(tag_list)] * len(case) # total probability on the state\n",
    "    total_idxState = [[-1] * len(tag_list)] * len(case) # optimal path (=[t-1] index) )\n",
    "    pos_case = ['n'] * len(case)\n",
    "    joint_prob = 0\n",
    "    \n",
    "    ### Step 1: Assigning output probabliities\n",
    "    for i, morph in enumerate(case): # 형태소 경우의 수\n",
    "        cur_syllable = morph[0]\n",
    "        for j, tag in enumerate(tag_list): # POS Tag 경우의 수\n",
    "            output_probState[i][j] = prob_TagWord[(tag, cur_syllable)]\n",
    "    \n",
    "    ### Step 2: Storing only maximum probabiliteis to each state by multiplying transition probabilities\n",
    "    for i, morph in enumerate(case): # 형태소 경우의 수\n",
    "        for j, tag in enumerate(tag_list): # POS Tag 경우의 수       \n",
    "            \n",
    "            cur_tag = tag_list[j]\n",
    "            cur_probState = total_probState[i][j]\n",
    "            \n",
    "            if i==0: # prev time에 START밖에 없으므로 max확률 찾을필요없이 그냥 다 저장한다.\n",
    "                total_probState[0][j] = prob_pTagcTag[('START', tag)] * output_probState[0][j]\n",
    "                # i==0일 때는 total_idxState[0][j]에 idx를 저장할 필요가 없다. 왜냐면, 어차피 무조건 START와 연결되기 때문이다.\n",
    "            else:\n",
    "                total_probState[i][j], total_idxState[i][j] = extract_maxProb(tag_list, total_probState, i, j, prob_pTagcTag)\n",
    "    \n",
    "    ### Step 3: Storing argmax index for connecting previous time\n",
    "    temp = [0] * len(tag_list)\n",
    "    for j, _ in enumerate(total_probState[-1]):\n",
    "        temp[j] = total_probState[-1][j] * prob_pTagcTag[(tag_list[j], 'END')]\n",
    "    \n",
    "    # only for END tag\n",
    "    end_idxState = np.where(np.array(temp) == np.array(temp).max())\n",
    "    end_idxState = end_idxState[0][0] # for extracting only index\n",
    "    \n",
    "    ### Step 4: Doing Back-tracking\n",
    "    tag_idx = -1\n",
    "    for i, x in enumerate(reversed(pos_case)):\n",
    "        idx = (len(pos_case)-1) - i\n",
    "        \n",
    "        if i==0: # last syllable\n",
    "            pos_case[idx] = tag_list[end_idxState]\n",
    "            joint_prob = total_probState[idx][end_idxState]\n",
    "            tag_idx = end_idxState # for sending next time\n",
    "        else:\n",
    "            pos_case[idx] = tag_list[total_idxState[idx][tag_idx]]\n",
    "            joint_prob *= total_probState[idx][tag_idx]\n",
    "            \n",
    "            tag_idx = total_idxState[idx][tag_idx] # for sending next time\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    all_pos_cases.append(pos_case)\n",
    "    all_jointprob_cases.append(joint_prob)\n",
    "    \n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_pos_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_jointprob_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_jointprob_cases = np.array(all_jointprob_cases)\n",
    "indices = np.where(all_jointprob_cases == all_jointprob_cases.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = np.where(all_jointprob_cases == all_jointprob_cases.max())\n",
    "answer_idx = answer[0][0] # 2개 이상이더라도 그냥 맨 처음에 있는 것을 argmax로 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morph_result[answer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_pos_cases[answer_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # dictionary filtering\n",
    "# cut_threshold = 30\n",
    "# freq_allTag = dict((k, v) for k, v in freq_allTag.items() if v > cut_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag 빈도수\n",
    "# tag bigram 빈도수\n",
    "# word, tag 쌍 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 전이확률\n",
    "# bigram확률"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
